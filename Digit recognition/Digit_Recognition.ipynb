{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Digit Recognition**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NN1tb8ho57ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding the imports**"
      ],
      "metadata": {
        "id": "fOzoldgQDbBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "#Sequential API: stacking layers of neural network on top of each other\n",
        "#Dense, Conv2D and Flatten: General components of CNN\n"
      ],
      "metadata": {
        "id": "Fahij7E2CPYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the model**"
      ],
      "metadata": {
        "id": "vDqesqM5Disz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Image width and height are set to 28 pixels\n",
        "2. Here, we use grayscale images, which are one channel and has 1 as the third dimension. \n",
        "3. We will train the data for 25 iterations and instruct the model that it should take into account 10 classes--> the digits 0 to 9.\n",
        "4. 20% of the data will be used for steering the training process away from a process called overfitting.\n",
        "5. Model training process to be specified as verbose,i.e. to specify all the possible output in the terminal."
      ],
      "metadata": {
        "id": "m8UTXAWP60Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 28, 28\n",
        "input_shape = (img_width, img_height, 1)\n",
        "batch_size = 1000\n",
        "no_epochs = 25\n",
        "no_classes = 10\n",
        "validation_split = 0.2\n",
        "verbosity = 1"
      ],
      "metadata": {
        "id": "NnTsxLqyDDHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the dataset**\n"
      ],
      "metadata": {
        "id": "88YdEU0iGC5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "def load_data():\n",
        "  return tensorflow.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "metadata": {
        "id": "wsQtJsRS6yuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the model**"
      ],
      "metadata": {
        "id": "iCH28IbTHNGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using model.add we stack a few layers on top of each other:\n",
        "\n",
        " starting the convolution layers for extracting features and Dense layers for actually converting the presence of features into a prediction.\n"
      ],
      "metadata": {
        "id": "7_CIk-ZkHn_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(4,kernel_size=(3,3), activation='relu',input_shape=input_shape))\n",
        "    model.add(Conv2D(8,kernel_size=(3,3), activation='relu'))\n",
        "    model.add(Conv2D(12,kernel_size=(3,3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(no_classes,activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "3aNKyFoFGnqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compiling the model**"
      ],
      "metadata": {
        "id": "AoUhleG5Jn8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just created a skeleton of the model. Compiling involves specifying an optimization mechanism and loss function."
      ],
      "metadata": {
        "id": "ZKT7y9JokeRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model):\n",
        "  model.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "drw4l5FcJL8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Traning and Testing**"
      ],
      "metadata": {
        "id": "8qStR4M3lJuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a model is trained, it must be tested against data that it hasn't seen before. \n",
        "\n",
        "This ensures that model can be generalized, meaning that it is also effective on data that it has not seen before.\n",
        "\n",
        "Our goal is to create a model that can both predict and generalize."
      ],
      "metadata": {
        "id": "Qe2AAcwllMeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, y_train):\n",
        "  model.fit(X_train, y_train,batch_size=batch_size,epochs=no_epochs,verbose=verbosity,shuffle=True,validation_split=validation_split)\n",
        "  return model\n",
        "\n",
        "# model testing\n",
        "def test_model(model,X_test,y_test):\n",
        "    score=model.evaluate(X_test,y_test,verbose=0)\n",
        "    print(f'Test loss: {score[0]}/Test accuracy: {score[1]}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "_DmQC4DHlClr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stacking stuff and starting the training process**"
      ],
      "metadata": {
        "id": "VcitV0dPo8GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)=load_data()\n",
        "\n",
        "#Normalize data\n",
        "(X_train,X_test)=(X_train/255.0,X_test/255.0)\n",
        "\n",
        "#reshape data\n",
        "(X_train,X_test)=(\n",
        "    X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1),\n",
        "    X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1),\n",
        ")"
      ],
      "metadata": {
        "id": "HtiaOrNMo51n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create and train the model**"
      ],
      "metadata": {
        "id": "Wf5n9rBoq-Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model=compile_model(model)\n",
        "model=train_model(model,X_train,y_train)\n",
        "model=test_model(model,X_test,y_test)"
      ],
      "metadata": {
        "id": "npHtKOI3qx5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187bd6d2-9072-40e4-a402-9fcb813d448a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "48/48 [==============================] - 4s 40ms/step - loss: 0.6800 - accuracy: 0.8287 - val_loss: 0.2261 - val_accuracy: 0.9388\n",
            "Epoch 2/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.1819 - accuracy: 0.9465 - val_loss: 0.1396 - val_accuracy: 0.9603\n",
            "Epoch 3/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.1160 - accuracy: 0.9659 - val_loss: 0.0998 - val_accuracy: 0.9716\n",
            "Epoch 4/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0819 - accuracy: 0.9759 - val_loss: 0.0808 - val_accuracy: 0.9759\n",
            "Epoch 5/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0637 - accuracy: 0.9808 - val_loss: 0.0700 - val_accuracy: 0.9799\n",
            "Epoch 6/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0534 - accuracy: 0.9843 - val_loss: 0.0729 - val_accuracy: 0.9782\n",
            "Epoch 7/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0434 - accuracy: 0.9876 - val_loss: 0.0670 - val_accuracy: 0.9798\n",
            "Epoch 8/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.0649 - val_accuracy: 0.9810\n",
            "Epoch 9/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
            "Epoch 10/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 0.0610 - val_accuracy: 0.9829\n",
            "Epoch 11/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0591 - val_accuracy: 0.9831\n",
            "Epoch 12/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0602 - val_accuracy: 0.9838\n",
            "Epoch 13/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.0583 - val_accuracy: 0.9844\n",
            "Epoch 14/25\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0639 - val_accuracy: 0.9829\n",
            "Epoch 15/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.0592 - val_accuracy: 0.9847\n",
            "Epoch 16/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0606 - val_accuracy: 0.9845\n",
            "Epoch 17/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0682 - val_accuracy: 0.9837\n",
            "Epoch 18/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0616 - val_accuracy: 0.9847\n",
            "Epoch 19/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0642 - val_accuracy: 0.9843\n",
            "Epoch 20/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0646 - val_accuracy: 0.9856\n",
            "Epoch 21/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0683 - val_accuracy: 0.9855\n",
            "Epoch 22/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0708 - val_accuracy: 0.9852\n",
            "Epoch 23/25\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0707 - val_accuracy: 0.9850\n",
            "Epoch 24/25\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0721 - val_accuracy: 0.9846\n",
            "Epoch 25/25\n",
            "48/48 [==============================] - 2s 35ms/step - loss: 8.8586e-04 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9862\n",
            "Test loss: 0.05812026932835579/Test accuracy: 0.9860000014305115\n"
          ]
        }
      ]
    }
  ]
}